# proj_ott
                                                                                 Decoding ott platform
                                                                                 
The landscape of streaming platforms i.e. OTT, which emerged in the early 2000s, witnessed its inception in India around 2008. Notably, industry giant Netflix made its foray into the Indian market in January 2016. As of today, OTT platforms have undeniably wielded a substantial influence on the entertainment industry, offering a plethora of captivating content. However, amidst the commendable progress, significant challenges have emerged, including hurdles in content discovery, content restriction and regulatory compliance.There is a struggle to strike a balance between artistic freedom and cultural and legal standards which is still going on as these platforms offering wide variety of content, including documentaries, TV shows, and movies. The complex terrain in question often gives rise to disputes regarding content appropriateness, which may impede the creative expression of filmmakers and content suppliers.
                                                                                    
                                                                                    Methodology

Data Preprocessing & Cleaning: The kaggle streaming service's database has around sixteen thousand entries, making it rather huge. Here, doing EDA and obtaining insightful information is the goal. It might potentially be useful in predicting a film's rating. The results were not significantly affected after data cleaning as we removed some rows with missing values. Then, we have removed the Age and Rotten Tomatoes attributes because they appear to have a lot of missing i.e. NaN values. The Age feature later was revisited because there was still some helpful information out there. The imdb feature can handle the prediction (with just 3% of missing information), hence the 'Rotten Tomatoes' column was eliminated. A few rows with missing data, such as "directors," "titles," and so on, are eliminated; characteristics with multiple inputs, such as "Directors," "Genres," "Nation," and "Language," are handled. We create further columns to further split out these elements. Since there will be many more columns, separated dataframe fields were made for "Directors," "Genres," "Country," and "Language." Depending on the study, these data frames were joined.  

2.2.	Exploratory data analysis (EDA): is a procedure that involves conducting a preliminary analysis of the data to identify any abnormalities and shape it so that it may be used to get some insights into solving our goal. The first step in the pre-processing of the database of this study was to visualize the raw data using descriptive statistics tables, skewness, and other descriptive terms like mean, max, and percentile values. It also involves preparing textual data for grouping purposes from userâ€™s text review and identifying and eliminating missing values.Then in cleaning of the textual data we have replaced missing values using different methods.Using imputation 'Empty string' was used to fill up the missing data in the director, cast, and country characteristics. There is a low percentage of nan values in the date_added and rating columns; removing these values won't have a significant impact on the model's construction. Therefore, we only remove the nan value that is present in the date_added and rating columns. We filled in the blanks with an empty string and have chosen to remove features that have fewer than 5% missing values outright. Additionally, the Capping method is used in the outlier removal procedure to eliminate outliers from the data where Q1, Q3 stand for each attribute's first and third quartiles as visualized.
 
    
